{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Global Residualization\n",
        "\n",
        "[Open in Colab](https://colab.research.google.com/github/mikarubi/abct/blob/main/docs-code/examples/1_residualn.ipynb){.btn .btn-dark .btn-sm}\n",
        "\n",
        "Many datasets and networks contain dominant global patterns that sometimes represent artifactual, trivial, or irrelevant structure. Correspondingly, analyses often seek to remove these patterns to uncover or accentuate interesting underlying structure. We use the term _global residualization_ to describe this removal.\n",
        "\n",
        "Here, we show approximate equivalence between three variants of global residualization across unsupervised learning, network science, and imaging neuroscience:\n",
        "\n",
        "- _First-component removal_: Subtraction of rank-one approximation of the data (common in unsupervised learning).\n",
        "- _Degree correction_: Subtraction of the normalized outer product of node degree vectors (common in network science).\n",
        "- _Global signal regression_: Regression of the mean time series signal from the time series data (common in imaging neuroscience).\n",
        "\n",
        "### Set up and load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install abct and download abct_utils.py\n",
        "base = \"https://github.com/mikarubi/abct/raw/refs/heads/main\"\n",
        "!wget --no-clobber {base}/docs-code/examples/abct_utils.py\n",
        "%pip install --quiet abct nilearn\n",
        "\n",
        "# Import modules\n",
        "import abct\n",
        "import numpy as np\n",
        "from abct_utils import W, X, C, ordw, ordc, not_eye, fig_scatter, fig_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Show original structural and correlation networks\n",
        "\n",
        "To show these relationships, we first consider the original structural and correlation networks in our example brain-imaging data. Each network contains 360 nodes (rows and columns) that denote cortical (brain) regions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig_imshow(W[np.ix_(ordw, ordw)],\n",
        "           \"Original structural network\",\n",
        "           \"inferno\").show()\n",
        "\n",
        "fig_imshow(C[np.ix_(ordc, ordc)],\n",
        "           \"Original correlation network\",\n",
        "           \"viridis\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Residualize structural and correlation networks\n",
        "\n",
        "We now apply the three variants of global residualization to these networks. Note that while the degree and first component are removed directly from the networks, the global signal is regressed out of the time series data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Residualize structural network\n",
        "Wd = abct.residualn(W, \"degree\")\n",
        "Wr = abct.residualn(W, \"rankone\")\n",
        "\n",
        "# Residualize correlation networks\n",
        "Cd = abct.residualn(C, \"degree\")\n",
        "Xg = abct.residualn(X.T, \"global\").T\n",
        "Xg = Xg / np.linalg.norm(Xg, axis=0, keepdims=True)\n",
        "Cg = Xg.T @ Xg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize residual structural and correlation networks\n",
        "\n",
        "We now visualize variants of the residual structural and correlation networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig_imshow(Wd[np.ix_(ordw, ordw)],\n",
        "           \"Struct. degree correction\",\n",
        "           \"inferno\").show()\n",
        "\n",
        "fig_imshow(Wr[np.ix_(ordw, ordw)],\n",
        "           \"Struct. first-component removal\",\n",
        "           \"inferno\").show()\n",
        "\n",
        "fig_imshow(Cd[np.ix_(ordc, ordc)],\n",
        "           \"Corr. degree correction\",\n",
        "           \"viridis\").show()\n",
        "\n",
        "fig_imshow(Cg[np.ix_(ordc, ordc)],\n",
        "           \"Corr. global signal regression\",\n",
        "           \"viridis\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we directly show the strong similarity between network weights after distinct residualizations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "r = np.corrcoef(Wr[not_eye], Wd[not_eye])[0, 1]\n",
        "fig_scatter(Wr[not_eye], Wd[not_eye], \n",
        "            \"Weights after first-component removal\",\n",
        "            \"Weights after degree correction\",\n",
        "            f\"Structural network (r = {r:.3f})\").show()\n",
        "\n",
        "r = np.corrcoef(Cg[not_eye], Cd[not_eye])[0, 1]\n",
        "fig_scatter(Cg[not_eye], Cd[not_eye], \n",
        "            \"Weights after global-signal regression\",\n",
        "            \"Weights after degree correction\",\n",
        "            f\"Correlation network (r = {r:.3f})\").show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}